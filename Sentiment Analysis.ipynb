{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a59af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./signed.csv\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10102f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54263af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./words.txt\", 'r', encoding='UTF-8') as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "lines.append('газпром')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66aaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Porter:\n",
    "    PERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "    REFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "    ADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "    PARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "    VERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "    NOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "    RVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "    DERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "    DER = re.compile(u\"ость?$\")\n",
    "    SUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "    I = re.compile(u\"и$\")\n",
    "    P = re.compile(u\"ь$\")\n",
    "    NN = re.compile(u\"нн$\")\n",
    "\n",
    "    def stem(word):\n",
    "        word = word.lower()\n",
    "        word = word.replace(u'ё', u'е')\n",
    "        m = re.match(Porter.RVRE, word)\n",
    "        if m is None:\n",
    "            return word\n",
    "        if m.groups():\n",
    "            pre = m.group(1)\n",
    "            rv = m.group(2)\n",
    "            temp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "            if temp == rv:\n",
    "                rv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "                temp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "                if temp != rv:\n",
    "                    rv = temp\n",
    "                    rv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "                else:\n",
    "                    temp = Porter.VERB.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = Porter.NOUN.sub('', rv, 1)\n",
    "                    else:\n",
    "                        rv = temp\n",
    "            else:\n",
    "                rv = temp\n",
    "            \n",
    "            rv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "            if re.match(Porter.DERIVATIONAL, rv):\n",
    "                rv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "            temp = Porter.P.sub('', rv, 1)\n",
    "            if temp == rv:\n",
    "                rv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "                rv = Porter.NN.sub(u'н', rv, 1)\n",
    "            else:\n",
    "                rv = temp\n",
    "            word = pre+rv\n",
    "        return word\n",
    "    stem=staticmethod(stem)\n",
    "def stemming(s):\n",
    "    s = s.split()\n",
    "    s = map(lambda ss: Porter.stem(ss), s)\n",
    "    return \" \".join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c25ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(set([stemming(line) for line in lines]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9287ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    for c in line:\n",
    "        if c in \"$#-0123456789\":\n",
    "            lines.remove(line)\n",
    "            break\n",
    "        if c in \"abcdefghijklmnopqrstuvxyz\":\n",
    "            lines.remove(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43ee087",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for i in range(len(lines)):\n",
    "    dictionary[lines[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173404d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Egor Kolyuzhnov\\AppData\\Local\\Temp\\ipykernel_1614056\\1720982303.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(df.shape[0] / idf)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "idf = np.zeros(len(dictionary))\n",
    "for i in range(df.shape[0]):\n",
    "    words = list(set(df['Text'].iloc[i].split()))\n",
    "    for w in words:\n",
    "        if w in dictionary:\n",
    "            idf[dictionary[w]] += 1\n",
    "idf = np.log(df.shape[0] / idf)\n",
    "for i in range(len(dictionary)):\n",
    "    if math.isinf(idf[i]):\n",
    "        idf[i] = 0\n",
    "\n",
    "def vectorize(text, dictionary):\n",
    "    words = text.split()\n",
    "    tf = np.zeros(len(dictionary))\n",
    "    for w in words:\n",
    "        if w in dictionary:\n",
    "            tf[dictionary[w]] += 1\n",
    "    tf /= len(words)\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1f4fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\egor kolyuzhnov\\anaconda3\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\users\\egor kolyuzhnov\\anaconda3\\lib\\site-packages (from scipy) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "import scipy\n",
    "\n",
    "vectors = scipy.sparse.csr_matrix((df.shape[0], len(dictionary)), dtype = np.float64).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "135cfb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    vector = vectorize(df['Text'].iloc[i], dictionary)\n",
    "    for j in range(len(dictionary)):\n",
    "        vectors[i, j] = vector[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "250d5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "_sum = 0\n",
    "for i in range(df.shape[0]):\n",
    "    for j in range(len(dictionary)):\n",
    "        _sum += vectors[i, j]\n",
    "mean = _sum / df.shape[0] / len(dictionary)\n",
    "_max = 0\n",
    "for i in range(df.shape[0]):\n",
    "    for j in range(len(dictionary)):\n",
    "        vectors[i, j] -= mean\n",
    "        _max = max(_max, abs(vectors[i, j]))\n",
    "for i in range(df.shape[0]):\n",
    "    for j in range(len(dictionary)):\n",
    "        vectors[i, j] /= _max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d37d74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\egor kolyuzhnov\\anaconda3\\lib\\site-packages (0.0.post4)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a2c2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7929db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = int(df.shape[0] * 0.8)\n",
    "X = vectors\n",
    "y = df['ChangeSign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab272d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0, verbose=10, n_jobs=-1, C=50, solver='saga').fit(X[:count], y[:count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X[:count], y[:count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X[count:], y[count:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34bdd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1041462",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./logistic.model\", 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7540b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
