{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e1f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7025861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.6\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0293071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb905e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.2806927606512\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "csv.field_size_limit(int(sys.maxsize / 100000000000))\n",
    "texts = []\n",
    "signs = []\n",
    "with open('./signed.csv', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        texts.append(row[2])\n",
    "        signs.append(row[5])\n",
    "word_counts = []\n",
    "for text in texts:\n",
    "    words = text.split()\n",
    "    word_counts.append(len(words))\n",
    "print(sum(word_counts) / len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e710a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3-64\\envs\\new_pytorch_env\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.463613748550415\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "sentences = []\n",
    "for text in texts:\n",
    "    sentences.append(text.split(' '))\n",
    "start = time.time()\n",
    "model = Word2Vec(sentences=sentences, vector_size=50, window=5, min_count=1, workers=20)\n",
    "model.save(\"word2vec.model\")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16edfae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('топлив', 0.82228022813797), ('нефт', 0.8111058473587036), ('энергоносител', 0.7799270749092102), ('электроэнерг', 0.7759563326835632), ('энергоресурс', 0.769345223903656), ('спг', 0.747270405292511), ('нефтепродукт', 0.7465770244598389), ('газов', 0.7330261468887329), ('газа»', 0.7305629253387451), ('нефтепровод', 0.7055534720420837)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('газ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46807aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for text in texts[1:]:\n",
    "    vectors.append([model.wv[w] for w in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a50492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "count = int(len(vectors) * 0.7)\n",
    "X = vectors\n",
    "classes = [-1, 0, 1]\n",
    "signs = signs[1:]\n",
    "for i in range(len(signs)):\n",
    "    signs[i] = int(signs[i])\n",
    "y = torch.zeros(len(vectors), 3, device='cuda:0')\n",
    "for i in range(len(vectors)):\n",
    "    y[i][classes.index(signs[i])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f795e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest = X[:count], X[count:]\n",
    "Ytrain, Ytest = y[:count], y[count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387832a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Time: 225.90056800842285s: Loss: 0.1659883199509949 Accuracy: 0.48246957027759113\n",
      "Epoch 1: Time: 227.76250529289246s: Loss: 0.09308606472966338 Accuracy: 0.5514551538285682\n",
      "Epoch 2: Time: 229.1815469264984s: Loss: 0.08169754562429506 Accuracy: 0.540391689585657\n",
      "Epoch 3: Time: 229.1042821407318s: Loss: 0.07983407995044933 Accuracy: 0.5599553859049942\n",
      "Epoch 4: Time: 229.00746297836304s: Loss: 0.07950238991123033 Accuracy: 0.5658161816153905\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=50, hidden_size=3, num_layers=1)\n",
    "lstm.to(\"cuda:0\")\n",
    "optimizer = optim.Adam(lstm.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "lstm.train()\n",
    "for epoch in range(500):\n",
    "    total_loss = 0\n",
    "    global_start = time.time()\n",
    "    for i in range(len(Xtrain)):\n",
    "        hidden = (\n",
    "            torch.rand(1, 3, device='cuda:0'),\n",
    "            torch.rand(1, 3, device='cuda:0')\n",
    "        )\n",
    "        x = Xtrain[i]\n",
    "        x = np.array(x)\n",
    "        _, hidden = lstm(torch.cuda.FloatTensor(x, device='cuda:0'), hidden)\n",
    "        yPred = hidden[0]\n",
    "        loss = loss_fn(yPred, Ytrain[i].reshape(1, 3))\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    count = 0\n",
    "    for i in range(len(Xtrain)):\n",
    "        hidden = (\n",
    "            torch.rand(1, 3, device='cuda:0'),\n",
    "            torch.rand(1, 3, device='cuda:0')\n",
    "        )\n",
    "        x = Xtrain[i]\n",
    "        x = np.array(x)\n",
    "        _, hidden = lstm(torch.cuda.FloatTensor(x, device='cuda:0'), hidden)\n",
    "        yPred = hidden[0]\n",
    "        yPred = yPred.reshape(-1)\n",
    "        _max = 0\n",
    "        j_max = 0\n",
    "        for j in range(len(yPred)):\n",
    "            if _max < yPred[j]:\n",
    "                _max = yPred[j]\n",
    "                j_max = j\n",
    "        if Ytrain[i][j_max] == 1:\n",
    "            count += 1\n",
    "    total_loss /= len(Xtrain)\n",
    "    global_end = time.time()\n",
    "    print(f\"Epoch {epoch}: Time: {global_end - global_start}s: Loss: {total_loss} Accuracy: {count / len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a295f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
